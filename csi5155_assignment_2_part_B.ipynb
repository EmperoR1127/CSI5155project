{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "csi5155_assignment_2_part_B.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/EmperoR1127/CSI5155_project/blob/master/csi5155_assignment_2_part_B.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zu7fkfDDpIVB",
        "colab_type": "code",
        "outputId": "72d45ebf-912a-462b-8b81-2bd9fae32016",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 125
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=email%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdocs.test%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive.photos.readonly%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fpeopleapi.readonly&response_type=code\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-UgFPIfDpPEb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# To support both python 2 and python 3\n",
        "from __future__ import division, print_function, unicode_literals\n",
        "\n",
        "# Common imports\n",
        "import numpy as np\n",
        "import os\n",
        "from scipy.io import arff\n",
        "import pandas as pd\n",
        "\n",
        "# to make this notebook's output stable across runs\n",
        "np.random.seed(42)\n",
        "\n",
        "# To plot pretty figures\n",
        "%matplotlib inline\n",
        "import matplotlib as mpl\n",
        "import matplotlib.pyplot as plt\n",
        "mpl.rc('axes', labelsize=14)\n",
        "mpl.rc('xtick', labelsize=12)\n",
        "mpl.rc('ytick', labelsize=12)\n",
        "\n",
        "# Where to save the figures\n",
        "PROJECT_ROOT_DIR = \"/content/drive/My Drive/Images/\"\n",
        "\n",
        "def save_fig(fig_id, tight_layout=True):\n",
        "    path = os.path.join(PROJECT_ROOT_DIR, \"images\", fig_id + \".png\")\n",
        "    print(\"Saving figure\", fig_id)\n",
        "    if tight_layout:\n",
        "        plt.tight_layout()\n",
        "    plt.savefig(path, format='png', dpi=300)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dwNLpKYPr_aa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#load four dataset\n",
        "seismic_bumps_data = pd.DataFrame(arff.loadarff('/content/drive/My Drive/Data/seismic-bumps.arff')[0])\n",
        "labor_neg_data = pd.read_csv(\"/content/drive/My Drive/Data/labor-neg.csv\")\n",
        "iris_data = pd.read_csv(\"/content/drive/My Drive/Data/iris.csv\")\n",
        "voting_data = pd.read_csv(\"/content/drive/My Drive/Data/voting-records.csv\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JN6fnyS9t04G",
        "colab_type": "code",
        "outputId": "aff2d9b6-21cc-438c-9a82-915e2e160b8c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        }
      },
      "source": [
        "#process the seismic_bumps_data\n",
        "#pre-process the train_set\n",
        "sb_train_labels = seismic_bumps_data[[\"class\"]].copy()\n",
        "sb_train_set = seismic_bumps_data.drop([\"class\"], axis=1)\n",
        "sb_train_labels[\"class\"] = sb_train_labels[\"class\"].map(lambda x: str(x)[2])\n",
        "sb_train_set_num = seismic_bumps_data.drop([\"seismic\",\"seismoacoustic\",\"shift\", \"ghazard\", \"class\"], axis=1)\n",
        "sb_train_set_cat = seismic_bumps_data.drop([\"genergy\",\"gpuls\",\"gdenergy\", \"gdpuls\", \"nbumps\", \"nbumps2\", \"nbumps3\", \"nbumps4\", \"nbumps5\", \"nbumps6\", \"nbumps7\", \"nbumps89\", \"energy\", \"maxenergy\", \"class\"], axis=1)\n",
        "#build the pipeline\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "sb_num_pipeline = Pipeline([('imputer', SimpleImputer(strategy=\"median\")),('std_scaler', StandardScaler()),])\n",
        "sb_full_pipeline = ColumnTransformer([(\"num\", sb_num_pipeline, list(sb_train_set_num)),(\"cat\", OneHotEncoder(), list(sb_train_set_cat)),])\n",
        "#prepare the data\n",
        "sb_train_set_prepared = sb_full_pipeline.fit_transform(sb_train_set)\n",
        "#prepare the target\n",
        "sb_encoder = LabelEncoder()\n",
        "sb_train_labels_prepared = sb_encoder.fit_transform(sb_train_labels)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/preprocessing/label.py:235: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SBT3H5bkfx7h",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#process the labor_neg_data\n",
        "ln_train_labels = labor_neg_data['class'].copy()\n",
        "ln_train_set = labor_neg_data.drop([\"class\"], axis = 1)\n",
        "ln_train_set_num = ln_train_set.drop([\"cola\",\"pension\",\"educ_allw\", \"vacation\", \"lngtrm_disabil\", \"dntl_ins\", \"bereavement\", \"empl_hplan\"], axis=1)\n",
        "ln_train_set_cat = ln_train_set.drop([\"dur\",\"wage1\",\"wage2\", \"wage3\", \"hours\", \"stby_pay\", \"shift_diff\", \"holidays\"], axis=1)\n",
        "#build the pipeline\n",
        "ln_num_pipeline = Pipeline([('imputer', SimpleImputer(strategy=\"median\")),('std_scaler', StandardScaler()),])\n",
        "ln_full_pipeline = ColumnTransformer([(\"num\", ln_num_pipeline, list(ln_train_set_num)),(\"cat\", OneHotEncoder(), list(ln_train_set_cat)),])\n",
        "#prepare the data\n",
        "ln_train_set_prepared = ln_full_pipeline.fit_transform(ln_train_set)\n",
        "#prepare the target\n",
        "ln_encoder = LabelEncoder()\n",
        "ln_train_labels_prepared = ln_encoder.fit_transform(ln_train_labels)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CJYFyJpRf390",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#process the iris_data\n",
        "ir_train_labels = iris_data['class'].copy()\n",
        "ir_train_set = iris_data.drop([\"class\"], axis = 1)\n",
        "#build the pipeline\n",
        "ir_num_pipeline = Pipeline([('imputer', SimpleImputer(strategy=\"median\")),('std_scaler', StandardScaler()),])\n",
        "ir_full_pipeline = ColumnTransformer([(\"num\", ir_num_pipeline, list(ir_train_set)),])\n",
        "#prepare the data\n",
        "ir_train_set_prepared = ir_full_pipeline.fit_transform(ir_train_set)\n",
        "#prepare the target\n",
        "ir_encoder = LabelEncoder()\n",
        "ir_train_labels_prepared = ir_encoder.fit_transform(ir_train_labels)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3GhBInUJ2O2R",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#process the voting_data\n",
        "vd_train_labels = voting_data['Class'].copy()\n",
        "vd_train_set = voting_data.drop([\"Class\"], axis = 1)\n",
        "#build the pipeline\n",
        "vd_full_pipeline = ColumnTransformer([(\"cat\", OneHotEncoder(), list(vd_train_set)),])\n",
        "#prepare the data\n",
        "vd_train_set_prepared = vd_full_pipeline.fit_transform(vd_train_set)\n",
        "#prepare the target\n",
        "vd_encoder = LabelEncoder()\n",
        "vd_train_labels_prepared = vd_encoder.fit_transform(vd_train_labels)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eOiTnG9Hf3ri",
        "colab_type": "code",
        "outputId": "256dc677-9474-44c9-81b0-92780f4c44a9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 140
        }
      },
      "source": [
        "#train the model using DECISION TREE algorithm with 10 fold cross validation\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.model_selection import cross_val_predict\n",
        "from sklearn.metrics import make_scorer\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.model_selection import cross_val_score\n",
        "score_method = make_scorer(accuracy_score)\n",
        "dt_clf = DecisionTreeClassifier()\n",
        "\n",
        "dt_sb_train_prediction = cross_val_predict(dt_clf.fit(sb_train_set_prepared, sb_train_labels_prepared), sb_train_set_prepared, sb_train_labels_prepared, cv=10)\n",
        "dt_sb_accuracy_score = accuracy_score(sb_train_labels_prepared, dt_sb_train_prediction)\n",
        "print(\"The accuracies of the DECISION TREE algorithm trained against seismic_bumps_data is + %f \" % dt_sb_accuracy_score)\n",
        "print(\"-----------------------------------------\")\n",
        "dt_ln_train_prediction = cross_val_predict(dt_clf.fit(ln_train_set_prepared, ln_train_labels_prepared), ln_train_set_prepared, ln_train_labels_prepared, cv=10)\n",
        "dt_ln_accuracy_score = accuracy_score(ln_train_labels_prepared, dt_ln_train_prediction)\n",
        "print(\"The accuracies of the DECISION TREE algorithm trained against labor_neg_data is + %f \" % dt_ln_accuracy_score)\n",
        "print(\"-----------------------------------------\")\n",
        "dt_ir_train_prediction = cross_val_predict(dt_clf.fit(ir_train_set_prepared, ir_train_labels_prepared), ir_train_set_prepared, ir_train_labels_prepared, cv=10)\n",
        "dt_ir_accuracy_score = accuracy_score(ir_train_labels_prepared, dt_ir_train_prediction)\n",
        "print(\"The accuracies of the DECISION TREE algorithm trained against iris_data is + %f \" % dt_ir_accuracy_score)\n",
        "print(\"-----------------------------------------\")\n",
        "dt_vd_train_prediction = cross_val_predict(dt_clf.fit(vd_train_set_prepared, vd_train_labels_prepared), vd_train_set_prepared, vd_train_labels_prepared, cv=10)\n",
        "dt_vd_accuracy_score = accuracy_score(vd_train_labels_prepared, dt_vd_train_prediction)\n",
        "print(\"The accuracies of the DECISION TREE algorithm trained against voting_data is + %f \" % dt_vd_accuracy_score)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The accuracies of the DECISION TREE algorithm trained against seismic_bumps_data is + 0.841718 \n",
            "-----------------------------------------\n",
            "The accuracies of the DECISION TREE algorithm trained against labor_neg_data is + 0.859649 \n",
            "-----------------------------------------\n",
            "The accuracies of the DECISION TREE algorithm trained against iris_data is + 0.953333 \n",
            "-----------------------------------------\n",
            "The accuracies of the DECISION TREE algorithm trained against voting_data is + 0.942529 \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6bl364PQiEmN",
        "colab_type": "code",
        "outputId": "11c7d4d9-b97a-4eac-fc69-c3d8ed5e1bf7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 140
        }
      },
      "source": [
        "#train the model using K NEAREST NEIGHBOURS algorithm with 10 fold cross validation\n",
        "from sklearn import neighbors\n",
        "n_neighbors = 5\n",
        "knn_clf = neighbors.KNeighborsClassifier(n_neighbors, weights='distance')\n",
        "\n",
        "knn_sb_train_prediction = cross_val_predict(knn_clf.fit(sb_train_set_prepared, sb_train_labels_prepared), sb_train_set_prepared, sb_train_labels_prepared, cv=10)\n",
        "knn_sb_accuracy_score = accuracy_score(sb_train_labels_prepared, knn_sb_train_prediction)\n",
        "print(\"The accuracies of K NEAREST NEIGHBOURS algorithm trained against seismic_bumps_data is + %f \" % knn_sb_accuracy_score)\n",
        "print(\"-----------------------------------------\")\n",
        "knn_ln_train_prediction = cross_val_predict(knn_clf.fit(ln_train_set_prepared, ln_train_labels_prepared), ln_train_set_prepared, ln_train_labels_prepared, cv=10)\n",
        "knn_ln_accuracy_score = accuracy_score(ln_train_labels_prepared, knn_ln_train_prediction)\n",
        "print(\"The accuracies of K NEAREST NEIGHBOURS algorithm trained against labor_neg_data is + %f \" % knn_ln_accuracy_score)\n",
        "print(\"-----------------------------------------\")\n",
        "knn_ir_train_prediction = cross_val_predict(knn_clf.fit(ir_train_set_prepared, ir_train_labels_prepared), ir_train_set_prepared, ir_train_labels_prepared, cv=10)\n",
        "knn_ir_accuracy_score = accuracy_score(ir_train_labels_prepared, knn_ir_train_prediction)\n",
        "print(\"The accuracies of K NEAREST NEIGHBOURS algorithm trained against iris_data is + %f \" % knn_ir_accuracy_score)\n",
        "print(\"-----------------------------------------\")\n",
        "knn_vd_train_prediction = cross_val_predict(knn_clf.fit(vd_train_set_prepared, vd_train_labels_prepared), vd_train_set_prepared, vd_train_labels_prepared, cv=10)\n",
        "knn_vd_accuracy_score = accuracy_score(vd_train_labels_prepared, knn_vd_train_prediction)\n",
        "print(\"The accuracies of K NEAREST NEIGHBOURS algorithm trained against voting_data is + %f \" % knn_vd_accuracy_score)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The accuracies of K NEAREST NEIGHBOURS algorithm trained against seismic_bumps_data is + 0.908282 \n",
            "-----------------------------------------\n",
            "The accuracies of K NEAREST NEIGHBOURS algorithm trained against labor_neg_data is + 0.947368 \n",
            "-----------------------------------------\n",
            "The accuracies of K NEAREST NEIGHBOURS algorithm trained against iris_data is + 0.953333 \n",
            "-----------------------------------------\n",
            "The accuracies of K NEAREST NEIGHBOURS algorithm trained against voting_data is + 0.921839 \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OhlUCQrzjHqU",
        "colab_type": "code",
        "outputId": "5c32355d-8ac9-42c5-9ac8-910bf66f7dee",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 140
        }
      },
      "source": [
        "#train the model using NAIVE BAYES algorithm with 10 fold cross validation\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "gnb_clf = GaussianNB()\n",
        "\n",
        "gnb_sb_train_prediction = cross_val_predict(gnb_clf.fit(sb_train_set_prepared, sb_train_labels_prepared), sb_train_set_prepared, sb_train_labels_prepared, cv=10)\n",
        "gnb_sb_accuracy_score = accuracy_score(sb_train_labels_prepared, gnb_sb_train_prediction)\n",
        "print(\"The accuracies of NAIVE BAYES algorithm trained against seismic_bumps_data is + %f \" % gnb_sb_accuracy_score)\n",
        "print(\"-----------------------------------------\")\n",
        "gnb_ln_train_prediction = cross_val_predict(gnb_clf.fit(ln_train_set_prepared, ln_train_labels_prepared), ln_train_set_prepared, ln_train_labels_prepared, cv=10)\n",
        "gnb_ln_accuracy_score = accuracy_score(ln_train_labels_prepared, gnb_ln_train_prediction)\n",
        "print(\"The accuracies of NAIVE BAYES algorithm trained against labor_neg_data is + %f \" % gnb_ln_accuracy_score)\n",
        "print(\"-----------------------------------------\")\n",
        "gnb_ir_train_prediction = cross_val_predict(gnb_clf.fit(ir_train_set_prepared, ir_train_labels_prepared), ir_train_set_prepared, ir_train_labels_prepared, cv=10)\n",
        "gnb_ir_accuracy_score = accuracy_score(ir_train_labels_prepared, gnb_ir_train_prediction)\n",
        "print(\"The accuracies of NAIVE BAYES algorithm trained against iris_data is + %f \" % gnb_ir_accuracy_score)\n",
        "print(\"-----------------------------------------\")\n",
        "gnb_vd_train_prediction = cross_val_predict(gnb_clf.fit(vd_train_set_prepared, vd_train_labels_prepared), vd_train_set_prepared, vd_train_labels_prepared, cv=10)\n",
        "gnb_vd_accuracy_score = accuracy_score(vd_train_labels_prepared, gnb_vd_train_prediction)\n",
        "print(\"The accuracies of NAIVE BAYES algorithm trained against voting_data is + %f \" % gnb_vd_accuracy_score)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The accuracies of NAIVE BAYES algorithm trained against seismic_bumps_data is + 0.382740 \n",
            "-----------------------------------------\n",
            "The accuracies of NAIVE BAYES algorithm trained against labor_neg_data is + 0.929825 \n",
            "-----------------------------------------\n",
            "The accuracies of NAIVE BAYES algorithm trained against iris_data is + 0.953333 \n",
            "-----------------------------------------\n",
            "The accuracies of NAIVE BAYES algorithm trained against voting_data is + 0.944828 \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p5MRRW6pjbOp",
        "colab_type": "code",
        "outputId": "47041e80-3ea2-4f27-f50b-31147b245d61",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 140
        }
      },
      "source": [
        "#train the model using RULE BASED algorithm with 10 fold cross validation\n",
        "from sklearn.dummy import DummyClassifier\n",
        "dc_clf = DummyClassifier(strategy='stratified')\n",
        "\n",
        "dc_sb_train_prediction = cross_val_predict(dc_clf.fit(sb_train_set_prepared, sb_train_labels_prepared), sb_train_set_prepared, sb_train_labels_prepared, cv=10)\n",
        "dc_sb_accuracy_score = accuracy_score(sb_train_labels_prepared, dc_sb_train_prediction)\n",
        "print(\"The accuracies of RULE BASED algorithm trained against seismic_bumps_data is + %f \" % dc_sb_accuracy_score)\n",
        "print(\"-----------------------------------------\")\n",
        "dc_ln_train_prediction = cross_val_predict(dc_clf.fit(ln_train_set_prepared, ln_train_labels_prepared), ln_train_set_prepared, ln_train_labels_prepared, cv=10)\n",
        "dc_ln_accuracy_score = accuracy_score(ln_train_labels_prepared, dc_ln_train_prediction)\n",
        "print(\"The accuracies of RULE BASED algorithm trained against labor_neg_data is + %f \" % dc_ln_accuracy_score)\n",
        "print(\"-----------------------------------------\")\n",
        "dc_ir_train_prediction = cross_val_predict(dc_clf.fit(ir_train_set_prepared, ir_train_labels_prepared), ir_train_set_prepared, ir_train_labels_prepared, cv=10)\n",
        "dc_ir_accuracy_score = accuracy_score(ir_train_labels_prepared, dc_ir_train_prediction)\n",
        "print(\"The accuracies of RULE BASED algorithm trained against iris_data is + %f \" % dc_ir_accuracy_score)\n",
        "print(\"-----------------------------------------\")\n",
        "dc_vd_train_prediction = cross_val_predict(dc_clf.fit(vd_train_set_prepared, vd_train_labels_prepared), vd_train_set_prepared, vd_train_labels_prepared, cv=10)\n",
        "dc_vd_accuracy_score = accuracy_score(vd_train_labels_prepared, dc_vd_train_prediction)\n",
        "print(\"The accuracies of RULE BASED algorithm trained against voting_data is + %f \" % dc_vd_accuracy_score)"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The accuracies of RULE BASED algorithm trained against seismic_bumps_data is + 0.875000 \n",
            "-----------------------------------------\n",
            "The accuracies of RULE BASED algorithm trained against labor_neg_data is + 0.456140 \n",
            "-----------------------------------------\n",
            "The accuracies of RULE BASED algorithm trained against iris_data is + 0.333333 \n",
            "-----------------------------------------\n",
            "The accuracies of RULE BASED algorithm trained against voting_data is + 0.531034 \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s9E0WIUaVw95",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#the function that calculate critical difference from Orange package\n",
        "def compute_CD(avranks, n, alpha=\"0.05\", test=\"nemenyi\"):\n",
        "    \"\"\"\n",
        "    Returns critical difference for Nemenyi or Bonferroni-Dunn test\n",
        "    according to given alpha (either alpha=\"0.05\" or alpha=\"0.1\") for average\n",
        "    ranks and number of tested datasets N. Test can be either \"nemenyi\" for\n",
        "    for Nemenyi two tailed test or \"bonferroni-dunn\" for Bonferroni-Dunn test.\n",
        "    \"\"\"\n",
        "    k = len(avranks)\n",
        "    d = {(\"nemenyi\", \"0.05\"): [0, 0, 1.959964, 2.343701, 2.569032, 2.727774,\n",
        "                               2.849705, 2.94832, 3.030879, 3.101730, 3.163684,\n",
        "                               3.218654, 3.268004, 3.312739, 3.353618, 3.39123,\n",
        "                               3.426041, 3.458425, 3.488685, 3.517073,\n",
        "                               3.543799],\n",
        "         (\"nemenyi\", \"0.1\"): [0, 0, 1.644854, 2.052293, 2.291341, 2.459516,\n",
        "                              2.588521, 2.692732, 2.779884, 2.854606, 2.919889,\n",
        "                              2.977768, 3.029694, 3.076733, 3.119693, 3.159199,\n",
        "                              3.195743, 3.229723, 3.261461, 3.291224, 3.319233],\n",
        "         (\"bonferroni-dunn\", \"0.05\"): [0, 0, 1.960, 2.241, 2.394, 2.498, 2.576,\n",
        "                                       2.638, 2.690, 2.724, 2.773],\n",
        "         (\"bonferroni-dunn\", \"0.1\"): [0, 0, 1.645, 1.960, 2.128, 2.241, 2.326,\n",
        "                                      2.394, 2.450, 2.498, 2.539]}\n",
        "    q = d[(test, alpha)]\n",
        "    cd = q[k] * (k * (k + 1) / (6.0 * n)) ** 0.5\n",
        "    return cd\n",
        "\n",
        "#function that draw Nemenyi diagram from Orange package\n",
        "def graph_ranks(avranks, names, cd=None, cdmethod=None, lowv=None, highv=None,\n",
        "                width=6, textspace=1, reverse=False, filename=None, **kwargs):\n",
        "    \"\"\"\n",
        "    Draws a CD graph, which is used to display  the differences in methods'\n",
        "    performance. See Janez Demsar, Statistical Comparisons of Classifiers over\n",
        "    Multiple Data Sets, 7(Jan):1--30, 2006.\n",
        "\n",
        "    Needs matplotlib to work.\n",
        "\n",
        "    The image is ploted on `plt` imported using\n",
        "    `import matplotlib.pyplot as plt`.\n",
        "\n",
        "    Args:\n",
        "        avranks (list of float): average ranks of methods.\n",
        "        names (list of str): names of methods.\n",
        "        cd (float): Critical difference used for statistically significance of\n",
        "            difference between methods.\n",
        "        cdmethod (int, optional): the method that is compared with other methods\n",
        "            If omitted, show pairwise comparison of methods\n",
        "        lowv (int, optional): the lowest shown rank\n",
        "        highv (int, optional): the highest shown rank\n",
        "        width (int, optional): default width in inches (default: 6)\n",
        "        textspace (int, optional): space on figure sides (in inches) for the\n",
        "            method names (default: 1)\n",
        "        reverse (bool, optional):  if set to `True`, the lowest rank is on the\n",
        "            right (default: `False`)\n",
        "        filename (str, optional): output file name (with extension). If not\n",
        "            given, the function does not write a file.\n",
        "    \"\"\"\n",
        "    try:\n",
        "        import matplotlib.pyplot as plt\n",
        "        from matplotlib.backends.backend_agg import FigureCanvasAgg\n",
        "    except ImportError:\n",
        "        raise ImportError(\"Function graph_ranks requires matplotlib.\")\n",
        "\n",
        "    width = float(width)\n",
        "    textspace = float(textspace)\n",
        "\n",
        "    def nth(l, n):\n",
        "        \"\"\"\n",
        "        Returns only nth elemnt in a list.\n",
        "        \"\"\"\n",
        "        n = lloc(l, n)\n",
        "        return [a[n] for a in l]\n",
        "\n",
        "    def lloc(l, n):\n",
        "        \"\"\"\n",
        "        List location in list of list structure.\n",
        "        Enable the use of negative locations:\n",
        "        -1 is the last element, -2 second last...\n",
        "        \"\"\"\n",
        "        if n < 0:\n",
        "            return len(l[0]) + n\n",
        "        else:\n",
        "            return n\n",
        "\n",
        "    def mxrange(lr):\n",
        "        \"\"\"\n",
        "        Multiple xranges. Can be used to traverse matrices.\n",
        "        This function is very slow due to unknown number of\n",
        "        parameters.\n",
        "\n",
        "        >>> mxrange([3,5])\n",
        "        [(0, 0), (0, 1), (0, 2), (1, 0), (1, 1), (1, 2)]\n",
        "\n",
        "        >>> mxrange([[3,5,1],[9,0,-3]])\n",
        "        [(3, 9), (3, 6), (3, 3), (4, 9), (4, 6), (4, 3)]\n",
        "\n",
        "        \"\"\"\n",
        "        if not len(lr):\n",
        "            yield ()\n",
        "        else:\n",
        "            # it can work with single numbers\n",
        "            index = lr[0]\n",
        "            if isinstance(index, int):\n",
        "                index = [index]\n",
        "            for a in range(*index):\n",
        "                for b in mxrange(lr[1:]):\n",
        "                    yield tuple([a] + list(b))\n",
        "\n",
        "    def print_figure(fig, *args, **kwargs):\n",
        "        canvas = FigureCanvasAgg(fig)\n",
        "        canvas.print_figure(*args, **kwargs)\n",
        "\n",
        "    sums = avranks\n",
        "\n",
        "    tempsort = sorted([(a, i) for i, a in enumerate(sums)], reverse=reverse)\n",
        "    ssums = nth(tempsort, 0)\n",
        "    sortidx = nth(tempsort, 1)\n",
        "    nnames = [names[x] for x in sortidx]\n",
        "\n",
        "    if lowv is None:\n",
        "        lowv = min(1, int(math.floor(min(ssums))))\n",
        "    if highv is None:\n",
        "        highv = max(len(avranks), int(math.ceil(max(ssums))))\n",
        "\n",
        "    cline = 0.4\n",
        "\n",
        "    k = len(sums)\n",
        "\n",
        "    lines = None\n",
        "\n",
        "    linesblank = 0\n",
        "    scalewidth = width - 2 * textspace\n",
        "\n",
        "    def rankpos(rank):\n",
        "        if not reverse:\n",
        "            a = rank - lowv\n",
        "        else:\n",
        "            a = highv - rank\n",
        "        return textspace + scalewidth / (highv - lowv) * a\n",
        "\n",
        "    distanceh = 0.25\n",
        "\n",
        "    if cd and cdmethod is None:\n",
        "        # get pairs of non significant methods\n",
        "\n",
        "        def get_lines(sums, hsd):\n",
        "            # get all pairs\n",
        "            lsums = len(sums)\n",
        "            allpairs = [(i, j) for i, j in mxrange([[lsums], [lsums]]) if j > i]\n",
        "            # remove not significant\n",
        "            notSig = [(i, j) for i, j in allpairs\n",
        "                      if abs(sums[i] - sums[j]) <= hsd]\n",
        "            # keep only longest\n",
        "\n",
        "            def no_longer(ij_tuple, notSig):\n",
        "                i, j = ij_tuple\n",
        "                for i1, j1 in notSig:\n",
        "                    if (i1 <= i and j1 > j) or (i1 < i and j1 >= j):\n",
        "                        return False\n",
        "                return True\n",
        "\n",
        "            longest = [(i, j) for i, j in notSig if no_longer((i, j), notSig)]\n",
        "\n",
        "            return longest\n",
        "\n",
        "        lines = get_lines(ssums, cd)\n",
        "        linesblank = 0.2 + 0.2 + (len(lines) - 1) * 0.1\n",
        "\n",
        "        # add scale\n",
        "        distanceh = 0.25\n",
        "        cline += distanceh\n",
        "\n",
        "    # calculate height needed height of an image\n",
        "    minnotsignificant = max(2 * 0.2, linesblank)\n",
        "    height = cline + ((k + 1) / 2) * 0.2 + minnotsignificant\n",
        "\n",
        "    fig = plt.figure(figsize=(width, height))\n",
        "    fig.set_facecolor('white')\n",
        "    ax = fig.add_axes([0, 0, 1, 1])  # reverse y axis\n",
        "    ax.set_axis_off()\n",
        "\n",
        "    hf = 1. / height  # height factor\n",
        "    wf = 1. / width\n",
        "\n",
        "    def hfl(l):\n",
        "        return [a * hf for a in l]\n",
        "\n",
        "    def wfl(l):\n",
        "        return [a * wf for a in l]\n",
        "\n",
        "\n",
        "    # Upper left corner is (0,0).\n",
        "    ax.plot([0, 1], [0, 1], c=\"w\")\n",
        "    ax.set_xlim(0, 1)\n",
        "    ax.set_ylim(1, 0)\n",
        "\n",
        "    def line(l, color='k', **kwargs):\n",
        "        \"\"\"\n",
        "        Input is a list of pairs of points.\n",
        "        \"\"\"\n",
        "        ax.plot(wfl(nth(l, 0)), hfl(nth(l, 1)), color=color, **kwargs)\n",
        "\n",
        "    def text(x, y, s, *args, **kwargs):\n",
        "        ax.text(wf * x, hf * y, s, *args, **kwargs)\n",
        "\n",
        "    line([(textspace, cline), (width - textspace, cline)], linewidth=0.7)\n",
        "\n",
        "    bigtick = 0.1\n",
        "    smalltick = 0.05\n",
        "\n",
        "    tick = None\n",
        "    for a in list(np.arange(lowv, highv, 0.5)) + [highv]:\n",
        "        tick = smalltick\n",
        "        if a == int(a):\n",
        "            tick = bigtick\n",
        "        line([(rankpos(a), cline - tick / 2),\n",
        "              (rankpos(a), cline)],\n",
        "             linewidth=0.7)\n",
        "\n",
        "    for a in range(lowv, highv + 1):\n",
        "        text(rankpos(a), cline - tick / 2 - 0.05, str(a),\n",
        "             ha=\"center\", va=\"bottom\")\n",
        "\n",
        "    k = len(ssums)\n",
        "\n",
        "    for i in range(math.ceil(k / 2)):\n",
        "        chei = cline + minnotsignificant + i * 0.2\n",
        "        line([(rankpos(ssums[i]), cline),\n",
        "              (rankpos(ssums[i]), chei),\n",
        "              (textspace - 0.1, chei)],\n",
        "             linewidth=0.7)\n",
        "        text(textspace - 0.2, chei, nnames[i], ha=\"right\", va=\"center\")\n",
        "\n",
        "    for i in range(math.ceil(k / 2), k):\n",
        "        chei = cline + minnotsignificant + (k - i - 1) * 0.2\n",
        "        line([(rankpos(ssums[i]), cline),\n",
        "              (rankpos(ssums[i]), chei),\n",
        "              (textspace + scalewidth + 0.1, chei)],\n",
        "             linewidth=0.7)\n",
        "        text(textspace + scalewidth + 0.2, chei, nnames[i],\n",
        "             ha=\"left\", va=\"center\")\n",
        "\n",
        "    if cd and cdmethod is None:\n",
        "        # upper scale\n",
        "        if not reverse:\n",
        "            begin, end = rankpos(lowv), rankpos(lowv + cd)\n",
        "        else:\n",
        "            begin, end = rankpos(highv), rankpos(highv - cd)\n",
        "\n",
        "        line([(begin, distanceh), (end, distanceh)], linewidth=0.7)\n",
        "        line([(begin, distanceh + bigtick / 2),\n",
        "              (begin, distanceh - bigtick / 2)],\n",
        "             linewidth=0.7)\n",
        "        line([(end, distanceh + bigtick / 2),\n",
        "              (end, distanceh - bigtick / 2)],\n",
        "             linewidth=0.7)\n",
        "        text((begin + end) / 2, distanceh - 0.05, \"CD\",\n",
        "             ha=\"center\", va=\"bottom\")\n",
        "\n",
        "        # no-significance lines\n",
        "        def draw_lines(lines, side=0.05, height=0.1):\n",
        "            start = cline + 0.2\n",
        "            for l, r in lines:\n",
        "                line([(rankpos(ssums[l]) - side, start),\n",
        "                      (rankpos(ssums[r]) + side, start)],\n",
        "                     linewidth=2.5)\n",
        "                start += height\n",
        "\n",
        "        draw_lines(lines)\n",
        "\n",
        "    elif cd:\n",
        "        begin = rankpos(avranks[cdmethod] - cd)\n",
        "        end = rankpos(avranks[cdmethod] + cd)\n",
        "        line([(begin, cline), (end, cline)],\n",
        "             linewidth=2.5)\n",
        "        line([(begin, cline + bigtick / 2),\n",
        "              (begin, cline - bigtick / 2)],\n",
        "             linewidth=2.5)\n",
        "        line([(end, cline + bigtick / 2),\n",
        "              (end, cline - bigtick / 2)],\n",
        "             linewidth=2.5)\n",
        "\n",
        "    if filename:\n",
        "        print_figure(fig, filename, **kwargs)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fkTK8InK9dOZ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "a76bc831-811a-4d3c-f97d-61f5f92f2f66"
      },
      "source": [
        "import math\n",
        "\n",
        "#calculate the critical difference between four algorithms\n",
        "avgrank = [2.0, 1.5, 2.3, 3.5]\n",
        "critical_diff = compute_CD(avgrank, n = 4)\n",
        "print(\"The critical difference between four algorithms is + %f\" % critical_diff)"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The critical difference between four algorithms is + 2.345195\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QQ9eUm-N-rFM",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 143
        },
        "outputId": "0ae9a211-f5b3-4556-828f-ef5c04f85248"
      },
      "source": [
        "#draw the Nemenyi diagarm\n",
        "alg_names = [\"Decision Tree\", \"Nearest Neighbours\", \"Naive Bayes\", \"Rule-based\"]\n",
        "graph_ranks(avranks= avgrank, names = alg_names, cd = critical_diff)"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAewAAAB+CAYAAADm8yKcAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nKQADm4iISAH+A/fi9QwVN0o0AAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 432x111.6 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1Xh3kb3Z_IRg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}