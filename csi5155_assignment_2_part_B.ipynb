{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "csi5155_assignment_2_part_B.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/EmperoR1127/CSI5155_project/blob/master/csi5155_assignment_2_part_B.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zu7fkfDDpIVB",
        "colab_type": "code",
        "outputId": "97a35d46-ec7b-4bd4-8a3c-867c654ef03d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 125
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=email%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdocs.test%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive.photos.readonly%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fpeopleapi.readonly&response_type=code\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-UgFPIfDpPEb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# To support both python 2 and python 3\n",
        "from __future__ import division, print_function, unicode_literals\n",
        "\n",
        "# Common imports\n",
        "import numpy as np\n",
        "import os\n",
        "from scipy.io import arff\n",
        "import pandas as pd\n",
        "\n",
        "# to make this notebook's output stable across runs\n",
        "np.random.seed(42)\n",
        "\n",
        "# To plot pretty figures\n",
        "%matplotlib inline\n",
        "import matplotlib as mpl\n",
        "import matplotlib.pyplot as plt\n",
        "mpl.rc('axes', labelsize=14)\n",
        "mpl.rc('xtick', labelsize=12)\n",
        "mpl.rc('ytick', labelsize=12)\n",
        "\n",
        "# Where to save the figures\n",
        "PROJECT_ROOT_DIR = \"/content/drive/My Drive/Images/\"\n",
        "\n",
        "def save_fig(fig_id, tight_layout=True):\n",
        "    path = os.path.join(PROJECT_ROOT_DIR, \"images\", fig_id + \".png\")\n",
        "    print(\"Saving figure\", fig_id)\n",
        "    if tight_layout:\n",
        "        plt.tight_layout()\n",
        "    plt.savefig(path, format='png', dpi=300)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dwNLpKYPr_aa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#load four dataset\n",
        "seismic_bumps_data = pd.DataFrame(arff.loadarff('/content/drive/My Drive/Data/seismic-bumps.arff')[0])\n",
        "labor_neg_data = pd.read_csv(\"/content/drive/My Drive/Data/labor-neg.csv\")\n",
        "iris_data = pd.read_csv(\"/content/drive/My Drive/Data/iris.csv\")\n",
        "voting_data = pd.read_csv(\"/content/drive/My Drive/Data/voting-records.csv\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JN6fnyS9t04G",
        "colab_type": "code",
        "outputId": "2d535888-55bd-4679-c5a2-dd544ce10898",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        }
      },
      "source": [
        "#process the seismic_bumps_data\n",
        "#pre-process the train_set\n",
        "sb_train_labels = seismic_bumps_data[[\"class\"]].copy()\n",
        "sb_train_set = seismic_bumps_data.drop([\"class\"], axis=1)\n",
        "sb_train_labels[\"class\"] = sb_train_labels[\"class\"].map(lambda x: str(x)[2])\n",
        "sb_train_set_num = seismic_bumps_data.drop([\"seismic\",\"seismoacoustic\",\"shift\", \"ghazard\", \"class\"], axis=1)\n",
        "sb_train_set_cat = seismic_bumps_data.drop([\"genergy\",\"gpuls\",\"gdenergy\", \"gdpuls\", \"nbumps\", \"nbumps2\", \"nbumps3\", \"nbumps4\", \"nbumps5\", \"nbumps6\", \"nbumps7\", \"nbumps89\", \"energy\", \"maxenergy\", \"class\"], axis=1)\n",
        "#build the pipeline\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "sb_num_pipeline = Pipeline([('imputer', SimpleImputer(strategy=\"median\")),('std_scaler', StandardScaler()),])\n",
        "sb_full_pipeline = ColumnTransformer([(\"num\", sb_num_pipeline, list(sb_train_set_num)),(\"cat\", OneHotEncoder(), list(sb_train_set_cat)),])\n",
        "#prepare the data\n",
        "sb_train_set_prepared = sb_full_pipeline.fit_transform(sb_train_set)\n",
        "#prepare the target\n",
        "sb_encoder = LabelEncoder()\n",
        "sb_train_labels_prepared = sb_encoder.fit_transform(sb_train_labels)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/preprocessing/label.py:235: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SBT3H5bkfx7h",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#process the labor_neg_data\n",
        "ln_train_labels = labor_neg_data['class'].copy()\n",
        "ln_train_set = labor_neg_data.drop([\"class\"], axis = 1)\n",
        "ln_train_set_num = ln_train_set.drop([\"cola\",\"pension\",\"educ_allw\", \"vacation\", \"lngtrm_disabil\", \"dntl_ins\", \"bereavement\", \"empl_hplan\"], axis=1)\n",
        "ln_train_set_cat = ln_train_set.drop([\"dur\",\"wage1\",\"wage2\", \"wage3\", \"hours\", \"stby_pay\", \"shift_diff\", \"holidays\"], axis=1)\n",
        "#build the pipeline\n",
        "ln_num_pipeline = Pipeline([('imputer', SimpleImputer(strategy=\"median\")),('std_scaler', StandardScaler()),])\n",
        "ln_full_pipeline = ColumnTransformer([(\"num\", ln_num_pipeline, list(ln_train_set_num)),(\"cat\", OneHotEncoder(), list(ln_train_set_cat)),])\n",
        "#prepare the data\n",
        "ln_train_set_prepared = ln_full_pipeline.fit_transform(ln_train_set)\n",
        "#prepare the target\n",
        "ln_encoder = LabelEncoder()\n",
        "ln_train_labels_prepared = ln_encoder.fit_transform(ln_train_labels)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CJYFyJpRf390",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#process the iris_data\n",
        "ir_train_labels = iris_data['class'].copy()\n",
        "ir_train_set = iris_data.drop([\"class\"], axis = 1)\n",
        "#build the pipeline\n",
        "ir_num_pipeline = Pipeline([('imputer', SimpleImputer(strategy=\"median\")),('std_scaler', StandardScaler()),])\n",
        "ir_full_pipeline = ColumnTransformer([(\"num\", ir_num_pipeline, list(ir_train_set)),])\n",
        "#prepare the data\n",
        "ir_train_set_prepared = ir_full_pipeline.fit_transform(ir_train_set)\n",
        "#prepare the target\n",
        "ir_encoder = LabelEncoder()\n",
        "ir_train_labels_prepared = ir_encoder.fit_transform(ir_train_labels)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3GhBInUJ2O2R",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#process the voting_data\n",
        "vd_train_labels = voting_data['Class'].copy()\n",
        "vd_train_set = voting_data.drop([\"Class\"], axis = 1)\n",
        "#build the pipeline\n",
        "vd_full_pipeline = ColumnTransformer([(\"cat\", OneHotEncoder(), list(vd_train_set)),])\n",
        "#prepare the data\n",
        "vd_train_set_prepared = vd_full_pipeline.fit_transform(vd_train_set)\n",
        "#prepare the target\n",
        "vd_encoder = LabelEncoder()\n",
        "vd_train_labels_prepared = vd_encoder.fit_transform(vd_train_labels)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eOiTnG9Hf3ri",
        "colab_type": "code",
        "outputId": "277737d0-b31d-4fef-c404-34723d8d437c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 140
        }
      },
      "source": [
        "#train the model using DECISION TREE algorithm with 10 fold cross validation\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.model_selection import cross_val_predict\n",
        "from sklearn.metrics import make_scorer\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.model_selection import cross_val_score\n",
        "score_method = make_scorer(accuracy_score)\n",
        "dt_clf = DecisionTreeClassifier()\n",
        "\n",
        "dt_sb_train_prediction = cross_val_predict(dt_clf.fit(sb_train_set_prepared, sb_train_labels_prepared), sb_train_set_prepared, sb_train_labels_prepared, cv=10)\n",
        "dt_sb_accuracy_score = accuracy_score(sb_train_labels_prepared, dt_sb_train_prediction)\n",
        "print(\"The accuracies of the DECISION TREE algorithm trained against seismic_bumps_data is + %f \" % dt_sb_accuracy_score)\n",
        "print(\"-----------------------------------------\")\n",
        "dt_ln_train_prediction = cross_val_predict(dt_clf.fit(ln_train_set_prepared, ln_train_labels_prepared), ln_train_set_prepared, ln_train_labels_prepared, cv=10)\n",
        "dt_ln_accuracy_score = accuracy_score(ln_train_labels_prepared, dt_ln_train_prediction)\n",
        "print(\"The accuracies of the DECISION TREE algorithm trained against labor_neg_data is + %f \" % dt_ln_accuracy_score)\n",
        "print(\"-----------------------------------------\")\n",
        "dt_ir_train_prediction = cross_val_predict(dt_clf.fit(ir_train_set_prepared, ir_train_labels_prepared), ir_train_set_prepared, ir_train_labels_prepared, cv=10)\n",
        "dt_ir_accuracy_score = accuracy_score(ir_train_labels_prepared, dt_ir_train_prediction)\n",
        "print(\"The accuracies of the DECISION TREE algorithm trained against iris_data is + %f \" % dt_ir_accuracy_score)\n",
        "print(\"-----------------------------------------\")\n",
        "dt_vd_train_prediction = cross_val_predict(dt_clf.fit(vd_train_set_prepared, vd_train_labels_prepared), vd_train_set_prepared, vd_train_labels_prepared, cv=10)\n",
        "dt_vd_accuracy_score = accuracy_score(vd_train_labels_prepared, dt_vd_train_prediction)\n",
        "print(\"The accuracies of the DECISION TREE algorithm trained against voting_data is + %f \" % dt_vd_accuracy_score)"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The accuracies of the DECISION TREE algorithm trained against seismic_bumps_data is + 0.847910 \n",
            "-----------------------------------------\n",
            "The accuracies of the DECISION TREE algorithm trained against labor_neg_data is + 0.877193 \n",
            "-----------------------------------------\n",
            "The accuracies of the DECISION TREE algorithm trained against iris_data is + 0.953333 \n",
            "-----------------------------------------\n",
            "The accuracies of the DECISION TREE algorithm trained against voting_data is + 0.949425 \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6bl364PQiEmN",
        "colab_type": "code",
        "outputId": "57b63b66-552b-4495-fe05-d97d77659ef6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 140
        }
      },
      "source": [
        "#train the model using K NEAREST NEIGHBOURS algorithm with 10 fold cross validation\n",
        "from sklearn import neighbors\n",
        "n_neighbors = 5\n",
        "knn_clf = neighbors.KNeighborsClassifier(n_neighbors, weights='distance')\n",
        "\n",
        "knn_sb_train_prediction = cross_val_predict(knn_clf.fit(sb_train_set_prepared, sb_train_labels_prepared), sb_train_set_prepared, sb_train_labels_prepared, cv=10)\n",
        "knn_sb_accuracy_score = accuracy_score(sb_train_labels_prepared, knn_sb_train_prediction)\n",
        "print(\"The accuracies of K NEAREST NEIGHBOURS algorithm trained against seismic_bumps_data is + %f \" % knn_sb_accuracy_score)\n",
        "print(\"-----------------------------------------\")\n",
        "knn_ln_train_prediction = cross_val_predict(knn_clf.fit(ln_train_set_prepared, ln_train_labels_prepared), ln_train_set_prepared, ln_train_labels_prepared, cv=10)\n",
        "knn_ln_accuracy_score = accuracy_score(ln_train_labels_prepared, knn_ln_train_prediction)\n",
        "print(\"The accuracies of K NEAREST NEIGHBOURS algorithm trained against labor_neg_data is + %f \" % knn_ln_accuracy_score)\n",
        "print(\"-----------------------------------------\")\n",
        "knn_ir_train_prediction = cross_val_predict(knn_clf.fit(ir_train_set_prepared, ir_train_labels_prepared), ir_train_set_prepared, ir_train_labels_prepared, cv=10)\n",
        "knn_ir_accuracy_score = accuracy_score(ir_train_labels_prepared, knn_ir_train_prediction)\n",
        "print(\"The accuracies of K NEAREST NEIGHBOURS algorithm trained against iris_data is + %f \" % knn_ir_accuracy_score)\n",
        "print(\"-----------------------------------------\")\n",
        "knn_vd_train_prediction = cross_val_predict(knn_clf.fit(vd_train_set_prepared, vd_train_labels_prepared), vd_train_set_prepared, vd_train_labels_prepared, cv=10)\n",
        "knn_vd_accuracy_score = accuracy_score(vd_train_labels_prepared, knn_vd_train_prediction)\n",
        "print(\"The accuracies of K NEAREST NEIGHBOURS algorithm trained against voting_data is + %f \" % knn_vd_accuracy_score)"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The accuracies of K NEAREST NEIGHBOURS algorithm trained against seismic_bumps_data is + 0.908282 \n",
            "-----------------------------------------\n",
            "The accuracies of K NEAREST NEIGHBOURS algorithm trained against labor_neg_data is + 0.947368 \n",
            "-----------------------------------------\n",
            "The accuracies of K NEAREST NEIGHBOURS algorithm trained against iris_data is + 0.953333 \n",
            "-----------------------------------------\n",
            "The accuracies of K NEAREST NEIGHBOURS algorithm trained against voting_data is + 0.921839 \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OhlUCQrzjHqU",
        "colab_type": "code",
        "outputId": "c7ccb8c7-63e7-48df-b8fa-d50d91fff35d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 140
        }
      },
      "source": [
        "#train the model using NAIVE BAYES algorithm with 10 fold cross validation\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "gnb_clf = GaussianNB()\n",
        "\n",
        "gnb_sb_train_prediction = cross_val_predict(gnb_clf.fit(sb_train_set_prepared, sb_train_labels_prepared), sb_train_set_prepared, sb_train_labels_prepared, cv=10)\n",
        "gnb_sb_accuracy_score = accuracy_score(sb_train_labels_prepared, gnb_sb_train_prediction)\n",
        "print(\"The accuracies of NAIVE BAYES algorithm trained against seismic_bumps_data is + %f \" % gnb_sb_accuracy_score)\n",
        "print(\"-----------------------------------------\")\n",
        "gnb_ln_train_prediction = cross_val_predict(gnb_clf.fit(ln_train_set_prepared, ln_train_labels_prepared), ln_train_set_prepared, ln_train_labels_prepared, cv=10)\n",
        "gnb_ln_accuracy_score = accuracy_score(ln_train_labels_prepared, gnb_ln_train_prediction)\n",
        "print(\"The accuracies of NAIVE BAYES algorithm trained against labor_neg_data is + %f \" % gnb_ln_accuracy_score)\n",
        "print(\"-----------------------------------------\")\n",
        "gnb_ir_train_prediction = cross_val_predict(gnb_clf.fit(ir_train_set_prepared, ir_train_labels_prepared), ir_train_set_prepared, ir_train_labels_prepared, cv=10)\n",
        "gnb_ir_accuracy_score = accuracy_score(ir_train_labels_prepared, gnb_ir_train_prediction)\n",
        "print(\"The accuracies of NAIVE BAYES algorithm trained against iris_data is + %f \" % gnb_ir_accuracy_score)\n",
        "print(\"-----------------------------------------\")\n",
        "gnb_vd_train_prediction = cross_val_predict(gnb_clf.fit(vd_train_set_prepared, vd_train_labels_prepared), vd_train_set_prepared, vd_train_labels_prepared, cv=10)\n",
        "gnb_vd_accuracy_score = accuracy_score(vd_train_labels_prepared, gnb_vd_train_prediction)\n",
        "print(\"The accuracies of NAIVE BAYES algorithm trained against voting_data is + %f \" % gnb_vd_accuracy_score)"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The accuracies of NAIVE BAYES algorithm trained against seismic_bumps_data is + 0.382740 \n",
            "-----------------------------------------\n",
            "The accuracies of NAIVE BAYES algorithm trained against labor_neg_data is + 0.929825 \n",
            "-----------------------------------------\n",
            "The accuracies of NAIVE BAYES algorithm trained against iris_data is + 0.953333 \n",
            "-----------------------------------------\n",
            "The accuracies of NAIVE BAYES algorithm trained against voting_data is + 0.944828 \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p5MRRW6pjbOp",
        "colab_type": "code",
        "outputId": "c4f7ced2-1882-4ce0-d2e4-3e6caa3ed7f5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 140
        }
      },
      "source": [
        "#train the model using RULE BASED algorithm with 10 fold cross validation\n",
        "from sklearn.dummy import DummyClassifier\n",
        "dc_clf = DummyClassifier(strategy='stratified')\n",
        "\n",
        "dc_sb_train_prediction = cross_val_predict(dc_clf.fit(sb_train_set_prepared, sb_train_labels_prepared), sb_train_set_prepared, sb_train_labels_prepared, cv=10)\n",
        "dc_sb_accuracy_score = accuracy_score(sb_train_labels_prepared, dc_sb_train_prediction)\n",
        "print(\"The accuracies of RULE BASED algorithm trained against seismic_bumps_data is + %f \" % dc_sb_accuracy_score)\n",
        "print(\"-----------------------------------------\")\n",
        "dc_ln_train_prediction = cross_val_predict(dc_clf.fit(ln_train_set_prepared, ln_train_labels_prepared), ln_train_set_prepared, ln_train_labels_prepared, cv=10)\n",
        "dc_ln_accuracy_score = accuracy_score(ln_train_labels_prepared, dc_ln_train_prediction)\n",
        "print(\"The accuracies of RULE BASED algorithm trained against labor_neg_data is + %f \" % dc_ln_accuracy_score)\n",
        "print(\"-----------------------------------------\")\n",
        "dc_ir_train_prediction = cross_val_predict(dc_clf.fit(ir_train_set_prepared, ir_train_labels_prepared), ir_train_set_prepared, ir_train_labels_prepared, cv=10)\n",
        "dc_ir_accuracy_score = accuracy_score(ir_train_labels_prepared, dc_ir_train_prediction)\n",
        "print(\"The accuracies of RULE BASED algorithm trained against iris_data is + %f \" % dc_ir_accuracy_score)\n",
        "print(\"-----------------------------------------\")\n",
        "dc_vd_train_prediction = cross_val_predict(dc_clf.fit(vd_train_set_prepared, vd_train_labels_prepared), vd_train_set_prepared, vd_train_labels_prepared, cv=10)\n",
        "dc_vd_accuracy_score = accuracy_score(vd_train_labels_prepared, dc_vd_train_prediction)\n",
        "print(\"The accuracies of RULE BASED algorithm trained against voting_data is + %f \" % dc_vd_accuracy_score)"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The accuracies of RULE BASED algorithm trained against seismic_bumps_data is + 0.876548 \n",
            "-----------------------------------------\n",
            "The accuracies of RULE BASED algorithm trained against labor_neg_data is + 0.543860 \n",
            "-----------------------------------------\n",
            "The accuracies of RULE BASED algorithm trained against iris_data is + 0.280000 \n",
            "-----------------------------------------\n",
            "The accuracies of RULE BASED algorithm trained against voting_data is + 0.494253 \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "91Exn_IeDWim",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 166
        },
        "outputId": "a7dd0651-ffe1-4943-a8ab-c32e372cbe53"
      },
      "source": [
        "import scikit_posthocs as sp\n",
        "x = [[3,1,4,2],[3,1,2,4],[1,1,1,4],[1,3,2,4]]\n",
        "sp.posthoc_nemenyi(x)"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>-1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.834769</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1.000000</td>\n",
              "      <td>-1.000000</td>\n",
              "      <td>0.834769</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.834769</td>\n",
              "      <td>0.834769</td>\n",
              "      <td>-1.000000</td>\n",
              "      <td>0.834769</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.834769</td>\n",
              "      <td>-1.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "          1         2         3         4\n",
              "1 -1.000000  1.000000  0.834769  1.000000\n",
              "2  1.000000 -1.000000  0.834769  1.000000\n",
              "3  0.834769  0.834769 -1.000000  0.834769\n",
              "4  1.000000  1.000000  0.834769 -1.000000"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3XHZNh-vH7_M",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 166
        },
        "outputId": "d767bf55-96fa-4553-e0c8-2a2e1ad61239"
      },
      "source": [
        "sp.posthoc_nemenyi_friedman(x)"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>-1.000000</td>\n",
              "      <td>0.900000</td>\n",
              "      <td>0.900000</td>\n",
              "      <td>0.516551</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.900000</td>\n",
              "      <td>-1.000000</td>\n",
              "      <td>0.823993</td>\n",
              "      <td>0.220908</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.900000</td>\n",
              "      <td>0.823993</td>\n",
              "      <td>-1.000000</td>\n",
              "      <td>0.670273</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.516551</td>\n",
              "      <td>0.220908</td>\n",
              "      <td>0.670273</td>\n",
              "      <td>-1.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "          0         1         2         3\n",
              "0 -1.000000  0.900000  0.900000  0.516551\n",
              "1  0.900000 -1.000000  0.823993  0.220908\n",
              "2  0.900000  0.823993 -1.000000  0.670273\n",
              "3  0.516551  0.220908  0.670273 -1.000000"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NUK6Eon6Idid",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}